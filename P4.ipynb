{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e21f4f",
   "metadata": {},
   "source": [
    "# **Practice 4 - Regular Expressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4a060ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz, re, json, os\n",
    "\n",
    "#doc = fitz.open(\"art_pruebas.pdf\")\n",
    "#texto = \"\\n\".join([page.get_text() for page in doc[2:]])  \n",
    "#print(texto[:1000])\n",
    "texto=\"CUENTO: EL ARCHIVISTA DEL SILENCIO. En la Biblioteca Central de Santívar existía un departamento poco conocido llamado Dependencia de Documentos Especiales, una oficina tan discreta que muchos la confundían con alguna entidad semejante a la [ETQ_GUB], la etiqueta con la que los archivistas señalaban toda referencia a organismos como la ONU, la UNESCO o cualquier dependencia gubernamental extranjera. Dentro de ese recinto trabajaba León, un archivista obsesionado con extraer, ordenar y reconstruir textos antiguos mediante reglas estrictas. Una mañana, León recibió un viejo PDF sin título. El director solo le dijo que “había que procesarlo según el protocolo”. León abrió el archivo y, como siempre, comenzó por identificar palabras terminadas en ado, ido, so o cho. El documento estaba repleto de términos como “deteriorado”, “hundido”, “apresado”, “confuso” y “hecho”. León los anotó en su Lista A, sabiendo que, más tarde, tendría que convertirlas a su forma infinitiva: deteriorar, hundir, apresar, confundir, hacer. Luego examinó la Lista B, la de las palabras con acento. El texto antiguo estaba lleno de frases como “camión”, “público”, “canción”, “había” y “país”. León sabía que, como dictaba el protocolo, debía eliminarles el acento, convirtiéndolas en cam ion, publico, cancion, habia y pais. Aunque detestaba la idea de despojarlas de su musicalidad original, la norma era inquebrantable. En la Lista C, anotó todas las menciones vinculadas a organismos políticos y gubernamentales. El manuscrito hacía referencia a varias instituciones: ONU, OMS, FAO, UNESCO y OEA. León calculó la similitud entre ellas; todas superaban el 0.5 debido a que compartían naturaleza funcional. Por ello las unificó bajo una sola etiqueta: [ETQ_GUB]. Al llegar a la s. Aunque detestaba la idea de despojarlas de su musicalidad original, la norma era inquebrantable. En la Lista C, anotó todas las menciones vinculadas a organismos políticos y gubernamentales. El manuscrito hacía referencia a varias instituciones: ONU, OMS, FAO, UNESCO y OEA. León calculó la similitud entre ellas; todas superaban el 0.5 debido a que compartían naturaleza funcional. Por ello las unificó bajo una sola etiqueta: [ETQ_GUB]. Al llegar a la Lista D, se encontró con algo que no esperaba: números telefónicos con formato americano escritos en los márgenes, probablemente añadidos por algún lector moderno. Eran combinaciones como (202)-555-0148 o 415-324-7781. El protocolo indicaba que debían eliminarse por completo, así que León los borró sin vacilar. Con todas las listas listas, el archivista emprendió el paso más complejo: reconstruir el texto. Primero eliminó manualmente todas las stopwords. Luego sustituyó las palabras de la Lista A por sus infinitivos, las de la Lista B por sus versiones sin acento, reemplazó cada organismo de la Lista C por [ETQ_GUB], y suprimió todos los números de la Lista D. Cuando terminó, el documento era casi irreconocible: una narración sintética, limpia, sin adornos, sin acentos, sin teléfonos, sin ruido. Sin embargo, algo extraño ocurrió. Al leerlo, el texto tomó la forma de un mensaje claro: “León, archivista, #HolaMundo cuando tu reconstruir este texto, tu despertar la memoria dormida de Santivar. La ciudad necesitar ordenar, limpiar, depurar su pasado para comprender su futuro. Tu ser el guardian del silencio.” León quedó inmóvil. En un acto reflejo, buscó más referencias, más números, más rastros, pero el PDF no tenía nada más. El mensaje parecía dirigido exclusivamente a él. Esa noche, al cerrar la biblioteca, escuchó un leve sonido proveniente del pasillo de Documentos Especiales. Era como si las páginas del archivo procesado se estuvieran mover, reacomodar, respirar. León pensó que tal vez todo había sido efecto del cansancio, aunque sabía que el protocolo no tenía contemplado nada para textos que parecían responder. Al día siguiente, el director lo esperaba con otro documento. Era aún más antiguo. —Necesitamos que aplique el mismo procedimiento —dijo con absoluta calma—. Este es solo el comienzo. Y León comprendió, sin necesidad de expresiones regulares, etiquetas ni listas, que la verdadera recolección apenas empezaba. hola@gmail.com.mx +55 1234 5678, 55-1234-5678, 55 12345678, +55 12345678, 55-12345678, ‪+525512345678‬, ‪+523312345678‬, ‪+528112345678 +34 91 1234 5678 +1 55 9876 5432+506 22 0001 3344, #HolaMundo #Python #Regeññx, #Regex101 #OpenAI #ChatGPT, #Datña-Science #MachineLearning #AI #NLP #100DaysOfCode, #México, 192.168.1.100,   300.1.1.1, 999.999.999.999  400.200.100.50 .123.456.78.90  \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a80710",
   "metadata": {},
   "source": [
    "### **Pattern 1: Palabras terminadas en ado, ido, to, so, cho**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "departamento - departamen\n",
      "conocido - conoc\n",
      "llamado - llam\n",
      "recinto - recin\n",
      "obsesionado - obsesion\n",
      "documento - documen\n",
      "repleto - reple\n",
      "deteriorado - deterior\n",
      "hundido - hund\n",
      "apresado - apres\n",
      "confuso - confu\n",
      "hecho - he\n",
      "acento - acen\n",
      "texto - tex\n",
      "acento - acen\n",
      "manuscrito - manuscri\n",
      "debido - deb\n",
      "manuscrito - manuscri\n",
      "debido - deb\n",
      "formato - forma\n",
      "completo - comple\n",
      "paso - pa\n",
      "texto - tex\n",
      "acento - acen\n",
      "documento - documen\n",
      "ruido - ru\n",
      "texto - tex\n",
      "texto - tex\n",
      "pasado - pas\n",
      "acto - ac\n",
      "dirigido - dirig\n",
      "sonido - son\n",
      "procesado - proces\n",
      "sido - s\n",
      "efecto - efec\n",
      "contemplado - contempl\n",
      "documento - documen\n",
      "procedimiento - procedimien\n"
     ]
    }
   ],
   "source": [
    "pattern1 = r\"\\b(\\w+)(ado|ido|to|so|cho)\\b\"\n",
    " \n",
    "match = re.findall(pattern1, texto)\n",
    "for rooted_word, termination in match:    print(f\"{rooted_word + termination} - {rooted_word}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6474a4",
   "metadata": {},
   "source": [
    "### **Pattern 2: Palabras con acentos/tildes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16c50012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Santívar',\n",
       " 'existía',\n",
       " 'confundían',\n",
       " 'León',\n",
       " 'León',\n",
       " 'recibió',\n",
       " 'título',\n",
       " 'había',\n",
       " 'según',\n",
       " 'León',\n",
       " 'abrió',\n",
       " 'comenzó',\n",
       " 'términos',\n",
       " 'León',\n",
       " 'anotó',\n",
       " 'más',\n",
       " 'tendría',\n",
       " 'examinó',\n",
       " 'camión',\n",
       " 'público',\n",
       " 'canción',\n",
       " 'había',\n",
       " 'país',\n",
       " 'León',\n",
       " 'sabía',\n",
       " 'debía',\n",
       " 'convirtiéndolas',\n",
       " 'anotó',\n",
       " 'políticos',\n",
       " 'hacía',\n",
       " 'León',\n",
       " 'calculó',\n",
       " 'compartían',\n",
       " 'unificó',\n",
       " 'anotó',\n",
       " 'políticos',\n",
       " 'hacía',\n",
       " 'León',\n",
       " 'calculó',\n",
       " 'compartían',\n",
       " 'unificó',\n",
       " 'encontró',\n",
       " 'números',\n",
       " 'telefónicos',\n",
       " 'márgenes',\n",
       " 'algún',\n",
       " 'debían',\n",
       " 'así',\n",
       " 'León',\n",
       " 'borró',\n",
       " 'emprendió',\n",
       " 'más',\n",
       " 'eliminó',\n",
       " 'sustituyó',\n",
       " 'reemplazó',\n",
       " 'suprimió',\n",
       " 'números',\n",
       " 'terminó',\n",
       " 'narración',\n",
       " 'sintética',\n",
       " 'teléfonos',\n",
       " 'ocurrió',\n",
       " 'tomó',\n",
       " 'León',\n",
       " 'León',\n",
       " 'quedó',\n",
       " 'inmóvil',\n",
       " 'buscó',\n",
       " 'más',\n",
       " 'más',\n",
       " 'números',\n",
       " 'más',\n",
       " 'tenía',\n",
       " 'más',\n",
       " 'parecía',\n",
       " 'él',\n",
       " 'escuchó',\n",
       " 'páginas',\n",
       " 'León',\n",
       " 'pensó',\n",
       " 'había',\n",
       " 'sabía',\n",
       " 'tenía',\n",
       " 'parecían',\n",
       " 'día',\n",
       " 'aún',\n",
       " 'más',\n",
       " 'León',\n",
       " 'comprendió',\n",
       " 'recolección',\n",
       " 'México']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern2 = r\"\\b\\w*[áéíóúÁÉÍÓÚ]\\w*\\b\"\n",
    "accented_word = re.findall(pattern2, texto)\n",
    "accented_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcffe30",
   "metadata": {},
   "source": [
    "### **Pattern 3: Siglas de organizaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6d2be5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CUENTO',\n",
       " 'DEL',\n",
       " 'SILENCIO',\n",
       " 'ONU',\n",
       " 'UNESCO',\n",
       " 'PDF',\n",
       " 'ONU',\n",
       " 'OMS',\n",
       " 'FAO',\n",
       " 'UNESCO',\n",
       " 'OEA',\n",
       " 'ONU',\n",
       " 'OMS',\n",
       " 'FAO',\n",
       " 'UNESCO',\n",
       " 'OEA',\n",
       " 'PDF',\n",
       " 'NLP']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern3 = r\"\\b[A-Z]{3,8}\\b\"\n",
    "re.findall(pattern3, texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bdd61",
   "metadata": {},
   "source": [
    "### **Pattern 4: Direcciones de correo electrónico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "715c82c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola@gmail.com.mx']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern4 = r\"\\b[a-zA-Z0-9._]+@[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)+\\b\"\n",
    "re.findall(pattern4, texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b982c",
   "metadata": {},
   "source": [
    "### **Pattern 5: Números telefónicos internacionales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9572cdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+525512345678',\n",
       " '+523312345678',\n",
       " '+528112345678',\n",
       " '+34 91 1234 5678',\n",
       " '+1 55 9876 5432',\n",
       " '+506 22 0001 3344']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern5 = r\"\\+(?:\\d{1,3})\\s*\\d{2}\\s*\\d{4}\\s*\\d{4}\"\n",
    "re.findall(pattern5, texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdebdf3",
   "metadata": {},
   "source": [
    "### **Pattern 6: Hashtags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfe7fb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#HolaMundo',\n",
       " '#HolaMundo',\n",
       " '#Python',\n",
       " '#Regeññx',\n",
       " '#Regex101',\n",
       " '#OpenAI',\n",
       " '#ChatGPT',\n",
       " '#Datña-Science',\n",
       " '#MachineLearning',\n",
       " '#AI',\n",
       " '#NLP',\n",
       " '#100DaysOfCode',\n",
       " '#México']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern6 = r\"#\\b[a-zA-Z0-9._áéíóúüñÁÉÍÓÚÜÑ-]+\\b\"\n",
    "re.findall(pattern6, texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977e7ca",
   "metadata": {},
   "source": [
    "### **Pattern 7: Direcciones IP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "286930e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['192.168.1.100',\n",
       " '300.1.1.1',\n",
       " '999.999.999.999',\n",
       " '400.200.100.50',\n",
       " '123.456.78.90']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern7 = r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\"\n",
    "re.findall(pattern7, texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fe828",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5d3df",
   "metadata": {},
   "source": [
    "**LISTA A cambiar todos los verbos a infinitivo mostrarlos y graficar los mas semejantes entre si (>=+- 0.5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41af3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['departamento', 'conocido', 'llamado', 'recinto', 'trabajaba', 'obsesionado', 'documento', 'estaba', 'repleto', 'deteriorado', 'hundido', 'apresado', 'confuso', 'hecho', 'acento', 'texto', 'estaba', 'dictaba', 'acento', 'detestaba', 'manuscrito', 'debido', 'detestaba', 'manuscrito', 'debido', 'esperaba', 'formato', 'indicaba', 'completo', 'paso', 'texto', 'acento', 'documento', 'ruido', 'texto', 'texto', 'pasado', 'acto', 'dirigido', 'sonido', 'procesado', 'sido', 'efecto', 'contemplado', 'esperaba', 'documento', 'procedimiento', 'empezaba']\n"
     ]
    }
   ],
   "source": [
    "pattern1 = r\"\\b(\\w+)(ado|ido|to|so|cho|aba)\\b\"\n",
    "matches = re.findall(pattern1, texto)\n",
    "\n",
    "participios = []\n",
    "\n",
    "for r, t in matches:\n",
    "    participios += [r + t]\n",
    "\n",
    "print(participios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c625fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participio -> infinitivo:\n",
      "departamento - departamento\n",
      "conocido - conocer\n",
      "llamado - llamar\n",
      "recinto - recinto\n",
      "trabajaba - analizar\n",
      "obsesionado - obsesionar\n",
      "documento - documento\n",
      "estaba - estaba\n",
      "repleto - repleto\n",
      "deteriorado - deteriorar\n",
      "hundido - hunder\n",
      "apresado - apresar\n",
      "confuso - confuso\n",
      "hecho - hecho\n",
      "acento - acento\n",
      "texto - texto\n",
      "estaba - estaba\n",
      "dictaba - dictaba\n",
      "acento - acento\n",
      "detestaba - detestaba\n",
      "manuscrito - manuscrito\n",
      "debido - deber\n",
      "detestaba - detestaba\n",
      "manuscrito - manuscrito\n",
      "debido - deber\n",
      "esperaba - esperaba\n",
      "formato - formato\n",
      "indicaba - indicaba\n",
      "completo - completo\n",
      "paso - paso\n",
      "texto - texto\n",
      "acento - acento\n",
      "documento - documento\n",
      "ruido - ruer\n",
      "texto - texto\n",
      "texto - texto\n",
      "pasado - pasar\n",
      "acto - acto\n",
      "dirigido - diriger\n",
      "sonido - soner\n",
      "procesado - procesar\n",
      "sido - ser\n",
      "efecto - efecto\n",
      "contemplado - contemplar\n",
      "esperaba - esperaba\n",
      "documento - documento\n",
      "procedimiento - procedimiento\n",
      "empezaba - empezaba\n"
     ]
    }
   ],
   "source": [
    "from NLP_Utilities.Tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "infinitivos = []\n",
    "for p in participios:\n",
    "    infinitivos = infinitivos + [tokenizer.lemmatize([p])[0]]\n",
    "\n",
    "print(\"participio -> infinitivo:\")\n",
    "\n",
    "for i in range(len(participios)):\n",
    "    print(participios[i], \"-\", infinitivos[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def indice_palabra(palabra, vec_palabras):\n",
    "    for j in range(len(vec_palabras)):\n",
    "        if vec_palabras[j] == palabra:\n",
    "            return j\n",
    "           \n",
    "def elimi_pal_repeti(token:list) -> list:\n",
    "    vec_pal_unicas = []\n",
    "    for i in range(len(token)):\n",
    "        if token[i] not in vec_pal_unicas:\n",
    "            vec_pal_unicas.append(token[i])\n",
    "    return vec_pal_unicas\n",
    "\n",
    "def matriz_concurrencia(texto:str) -> np.ndarray:\n",
    "    tokenizer = Tokenizer()\n",
    "    text_toke = tokenizer.tokenize(texto)\n",
    "    vec_pal_unicas = elimi_pal_repeti(text_toke)\n",
    "    n = len(vec_pal_unicas)\n",
    "    matriz_concurrencia = np.zeros((n,n))\n",
    "    for i in range (len(text_toke)-1):\n",
    "        pal = text_toke[i]\n",
    "        pal_siguien = text_toke[i+1]\n",
    "        indice_pal = indice_palabra(pal, vec_pal_unicas)\n",
    "        indice_pal_siguien = indice_palabra(pal_siguien, vec_pal_unicas)\n",
    "\n",
    "\n",
    "        if indice_pal == indice_pal_siguien:\n",
    "            matriz_concurrencia[indice_pal][indice_pal_siguien] += 1\n",
    "        else:\n",
    "            matriz_concurrencia[indice_pal_siguien][indice_pal] += 1  \n",
    "    return matriz_concurrencia\n",
    "\n",
    "def similitud_coseno(palabra1, palabra2, matriz_concurrencia, texto:str) -> float:\n",
    "    tokenizer = Tokenizer()\n",
    "    text_toke = tokenizer.tokenize(texto)\n",
    "    vec_pal_unicas = elimi_pal_repeti(text_toke)\n",
    "    indice_pal1 = indice_palabra(palabra1, vec_pal_unicas)\n",
    "    indice_pal2 = indice_palabra(palabra2, vec_pal_unicas)\n",
    "    \n",
    "    vec1 = matriz_concurrencia[indice_pal1]\n",
    "    vec2 = matriz_concurrencia[indice_pal2]\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    cosine_similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0566967",
   "metadata": {},
   "source": [
    "**LISTA B quitar todos los acentos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "788e65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern2 = r\"\\b\\w*[áéíóúÁÉÍÓÚ]\\w*\\b\"\n",
    "accented_word = re.findall(pattern2, texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b74dfc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras sin acentos: \n",
      " ['Santivar', 'existia', 'confundian', 'Leon', 'Leon', 'recibio', 'titulo', 'habia', 'segun', 'Leon', 'abrio', 'comenzo', 'terminos', 'Leon', 'anoto', 'mas', 'tendria', 'examino', 'camion', 'publico', 'cancion', 'habia', 'pais', 'Leon', 'sabia', 'debia', 'convirtiendolas', 'anoto', 'politicos', 'hacia', 'Leon', 'calculo', 'compartian', 'unifico', 'anoto', 'politicos', 'hacia', 'Leon', 'calculo', 'compartian', 'unifico', 'encontro', 'numeros', 'telefonicos', 'margenes', 'algun', 'debian', 'asi', 'Leon', 'borro', 'emprendio', 'mas', 'elimino', 'sustituyo', 'reemplazo', 'suprimio', 'numeros', 'termino', 'narracion', 'sintetica', 'telefonos', 'ocurrio', 'tomo', 'Leon', 'Leon', 'quedo', 'inmovil', 'busco', 'mas', 'mas', 'numeros', 'mas', 'tenia', 'mas', 'parecia', 'el', 'escucho', 'paginas', 'Leon', 'penso', 'habia', 'sabia', 'tenia', 'parecian', 'dia', 'aun', 'mas', 'Leon', 'comprendio', 'recoleccion', 'Mexico']\n",
      "Total palabras sin acentos: 91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_accented_word = []\n",
    "def remove_accents(word):\n",
    "    map = {\"á\":\"a\",\"é\":\"e\",\"í\":\"i\",\"ó\":\"o\",\"ú\":\"u\",\"Á\":\"A\",\"É\":\"E\",\"Í\":\"I\"  ,\"Ó\":\"O\",\"Ú\":\"U\"}\n",
    "\n",
    "    def replacce(m):\n",
    "        letra = m[0]      \n",
    "        return map[letra]\n",
    "    \n",
    "    return re.sub(r\"[áéíóúÁÉÍÓÚ]\", replacce, word)\n",
    "\n",
    "for w in accented_word:\n",
    "    n_accented_word += [remove_accents(w)]\n",
    "\n",
    "print('Palabras sin acentos: \\n', n_accented_word)\n",
    "print('Total palabras sin acentos:', len(n_accented_word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed150d09",
   "metadata": {},
   "source": [
    "**Quitar stopwods con expresiones regulares, recostruir el texto sin stopwords, sin las palabras con acentos; sustituyendo las palabras de A(una lista de palabras terminadas en ado,ido,to,so,cho) por su etiqueta; sustituir C(una lista de palabras con dependecias gubernamentales) por la palabra \"dependencias\" y quitando D (Una lista con #de telefonos, redes sociales, correos electronicos, IP'S, #)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "653b2ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUENTO: EL ARCHIVISTA DEL SILENCIO. En  Biblioteca Central  Santívar existía  departamento  conocido llamado Dependencia  Documentos Especiales,  oficina  discreta  muchos  confundían  alguna entidad semejante   [ETQ_GUB],  etiqueta     archivistas señalaban toda referencia  organismos   ONU,  UNESCO  cualquier dependencia gubernamental extranjera. Dentro   recinto analizar León,  archivista obsesionado  extraer, ordenar  reconstruir textos antiguos mediante reglas estrictas. Una mañana, León recibió  viejo PDF  título. El director solo  dijo  “  procesarlo según  protocolo”. León abrió  archivo ,  siempre, comenzó  identificar palabras terminadas  ado, ido, so  cho. El documento estaba repleto  términos  “deteriorado”, “hundido”, “apresado”, “confuso”  “hecho”. León  anotó   Lista A, sabiendo ,  tarde, tendría  convertirlas   forma infinitiva: deteriorar, hundir, apresar, confundir, hacer. Luego examinó  Lista B,    palabras  acento. El texto antiguo estaba lleno  frases  “camión”, “público”, “canción”, “”  “país”. León sabía ,  dictaba  protocolo, debía eliminarles  acento, convirtiéndolas  cam ion, publico, cancion, habia  pais. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anotó todas  menciones vinculadas  organismos políticos  gubernamentales. El manuscrito hacía referencia  varias instituciones: ONU, OMS, FAO, UNESCO  OEA. León calculó  similitud  ellas; todas superaban  0.5 debido   compartían naturaleza funcional. Por ello  unificó bajo  sola etiqueta: [ETQ_GUB]. Al llegar   s. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anotó todas  menciones vinculadas  organismos políticos  gubernamentales. El manuscrito hacía referencia  varias instituciones: ONU, OMS, FAO, UNESCO  OEA. León calculó  similitud  ellas; todas superaban  0.5 debido   compartían naturaleza funcional. Por ello  unificó bajo  sola etiqueta: [ETQ_GUB]. Al llegar   Lista D,  encontró  algo  no esperaba: números telefónicos  formato americano escritos   márgenes, probablemente añadidos  algún lector moderno. Eran combinaciones  (202)-555-0148  415-324-7781. El protocolo indicaba  debían eliminarse  completo, así  León  borró  vacilar. Con todas  listas listas,  archivista emprendió  paso  complejo: reconstruir  texto. Primero eliminó manualmente todas  stopwords. Luego sustituyó  palabras   Lista A   infinitivos,    Lista B   versiones  acento, reemplazó cada organismo   Lista C  [ETQ_GUB],  suprimió todos  números   Lista D. Cuando terminó,  documento era casi irreconocible:  narración sintética, limpia,  adornos,  acentos,  teléfonos,  ruido. Sin embargo, algo extraño ocurrió. Al leerlo,  texto tomó  forma   mensaje claro: “León, archivista, #HolaMundo   reconstruir  texto,  despertar  memoria dormida  Santivar. La ciudad necesitar ordenar, limpiar, depurar  pasado  comprender  futuro. Tu ser  guardian  silencio.” León quedó inmóvil. En  acto reflejo, buscó  referencias,  números,  rastros,   PDF no tenía nada . El mensaje parecía dirigido exclusivamente  él. Esa noche,  cerrar  biblioteca, escuchó  leve sonido proveniente  pasillo  Documentos Especiales. Era    páginas  archivo procesado  estuvieran mover, reacomodar, respirar. León pensó  tal vez todo  sido efecto  cansancio, aunque sabía   protocolo no tenía contemplado nada  textos  parecían responder. Al día siguiente,  director  esperaba  otro documento. Era aún  antiguo. —Necesitamos  aplique  mismo procedimiento —dijo  absoluta calma—. Este es solo  comienzo. Y León comprendió,  necesidad  expresiones regulares, etiquetas ni listas,   verdadera recolección apenas empezaba. hola@gmail.com.mx +55 1234 5678, 55-1234-5678, 55 12345678, +55 12345678, 55-12345678, ‪+525512345678‬, ‪+523312345678‬, ‪+528112345678 +34 91 1234 5678 +1 55 9876 5432+506 22 0001 3344, #HolaMundo #Python #Regeññx, #Regex101 #OpenAI #ChatGPT, #Datña-Science #MachineLearning #AI #NLP #100DaysOfCode, #México, 192.168.1.100,   300.1.1.1, 999.999.999.999  400.200.100.50 .123.456.78.90  \n"
     ]
    }
   ],
   "source": [
    "text = texto\n",
    "stopwords = [\n",
    "        'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',\n",
    "        'de', 'del', 'a', 'al', 'en', 'por', 'para', 'con', 'sin', 'sobre', 'entre',\n",
    "        'y', 'e', 'o', 'u', 'pero', 'sino', 'que', 'si', 'como',\n",
    "        'este', 'esta', 'estos', 'estas', 'ese', 'esa', 'esos', 'esas',\n",
    "        'aquel', 'aquella', 'aquellos', 'aquellas',\n",
    "        'su', 'sus', 'mi', 'mis', 'tu', 'tus', 'nuestro', 'nuestra', 'nuestros', 'nuestras',\n",
    "        'se', 'me', 'te', 'le', 'lo', 'les', 'nos',\n",
    "        'muy', 'más', 'menos', 'tan', 'tanto', 'mucho', 'poco',\n",
    "        'donde', 'cuando', 'cual', 'cuales', 'quien', 'quienes',\n",
    "        'hay', 'ha', 'han', 'he', 'hemos', 'había', 'habían'\n",
    "    ]\n",
    "    \n",
    "    # Crear patrón de stopwords\n",
    "stopwords_pattern = r'\\b(' + '|'.join(stopwords) + r')\\b'\n",
    "\n",
    "\n",
    "texto_procesado = re.sub(stopwords_pattern, '', text)\n",
    "print(texto_procesado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ff792b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUENTO: EL ARCHIVISTA DEL SILENCIO. En  Biblioteca Central  Santivar existia  departamento  conocido llamado Dependencia  Documentos Especiales,  oficina  discreta  muchos  confundian  alguna entidad semejante   [ETQ_GUB],  etiqueta     archivistas señalaban toda referencia  organismos   ONU,  UNESCO  cualquier dependencia gubernamental extranjera. Dentro   recinto analizar Leon,  archivista obsesionado  extraer, ordenar  reconstruir textos antiguos mediante reglas estrictas. Una mañana, Leon recibio  viejo PDF  titulo. El director solo  dijo  “  procesarlo segun  protocolo”. Leon abrio  archivo ,  siempre, comenzo  identificar palabras terminadas  ado, ido, so  cho. El documento estaba repleto  terminos  “deteriorado”, “hundido”, “apresado”, “confuso”  “hecho”. Leon  anoto   Lista A, sabiendo ,  tarde, tendria  convertirlas   forma infinitiva: deteriorar, hundir, apresar, confundir, hacer. Luego examino  Lista B,    palabras  acento. El texto antiguo estaba lleno  frases  “camion”, “publico”, “cancion”, “”  “pais”. Leon sabia ,  dictaba  protocolo, debia eliminarles  acento, convirtiendolas  cam ion, publico, cancion, habia  pais. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anoto todas  menciones vinculadas  organismos politicos  gubernamentales. El manuscrito hacia referencia  varias instituciones: ONU, OMS, FAO, UNESCO  OEA. Leon calculo  similitud  ellas; todas superaban  0.5 debido   compartian naturaleza funcional. Por ello  unifico bajo  sola etiqueta: [ETQ_GUB]. Al llegar   s. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anoto todas  menciones vinculadas  organismos politicos  gubernamentales. El manuscrito hacia referencia  varias instituciones: ONU, OMS, FAO, UNESCO  OEA. Leon calculo  similitud  ellas; todas superaban  0.5 debido   compartian naturaleza funcional. Por ello  unifico bajo  sola etiqueta: [ETQ_GUB]. Al llegar   Lista D,  encontro  algo  no esperaba: numeros telefonicos  formato americano escritos   margenes, probablemente añadidos  algun lector moderno. Eran combinaciones  (202)-555-0148  415-324-7781. El protocolo indicaba  debian eliminarse  completo, asi  Leon  borro  vacilar. Con todas  listas listas,  archivista emprendio  paso  complejo: reconstruir  texto. Primero elimino manualmente todas  stopwords. Luego sustituyo  palabras   Lista A   infinitivos,    Lista B   versiones  acento, reemplazo cada organismo   Lista C  [ETQ_GUB],  suprimio todos  numeros   Lista D. Cuando termino,  documento era casi irreconocible:  narracion sintetica, limpia,  adornos,  acentos,  telefonos,  ruido. Sin embargo, algo extraño ocurrio. Al leerlo,  texto tomo  forma   mensaje claro: “Leon, archivista, #HolaMundo   reconstruir  texto,  despertar  memoria dormida  Santivar. La ciudad necesitar ordenar, limpiar, depurar  pasado  comprender  futuro. Tu ser  guardian  silencio.” Leon quedo inmovil. En  acto reflejo, busco  referencias,  numeros,  rastros,   PDF no tenia nada . El mensaje parecia dirigido exclusivamente  el. Esa noche,  cerrar  biblioteca, escucho  leve sonido proveniente  pasillo  Documentos Especiales. Era    paginas  archivo procesado  estuvieran mover, reacomodar, respirar. Leon penso  tal vez todo  sido efecto  cansancio, aunque sabia   protocolo no tenia contemplado nada  textos  parecian responder. Al dia siguiente,  director  esperaba  otro documento. Era aun  antiguo. —Necesitamos  aplique  mismo procedimiento —dijo  absoluta calma—. Este es solo  comienzo. Y Leon comprendio,  necesidad  expresiones regulares, etiquetas ni listas,   verdadera recoleccion apenas empezaba. hola@gmail.com.mx +55 1234 5678, 55-1234-5678, 55 12345678, +55 12345678, 55-12345678, ‪+525512345678‬, ‪+523312345678‬, ‪+528112345678 +34 91 1234 5678 +1 55 9876 5432+506 22 0001 3344, #HolaMundo #Python #Regeññx, #Regex101 #OpenAI #ChatGPT, #Datña-Science #MachineLearning #AI #NLP #100DaysOfCode, #Mexico, 192.168.1.100,   300.1.1.1, 999.999.999.999  400.200.100.50 .123.456.78.90  \n"
     ]
    }
   ],
   "source": [
    "pattern_accent = r\"\\b\\w*[áéíóúÁÉÍÓÚ]\\w*\\b\"\n",
    "\n",
    "def remove_accents(word):\n",
    "    mapa = {\n",
    "        \"á\":\"a\",\"é\":\"e\",\"í\":\"i\",\"ó\":\"o\",\"ú\":\"u\",\n",
    "        \"Á\":\"A\",\"É\":\"E\",\"Í\":\"I\",\"Ó\":\"O\",\"Ú\":\"U\"\n",
    "    }\n",
    "    def replace_match(m):\n",
    "        return mapa[m.group(0)]\n",
    "\n",
    "    return re.sub(r\"[áéíóúÁÉÍÓÚ]\", replace_match, word)\n",
    "\n",
    "accented_words = re.findall(pattern_accent, texto_procesado)\n",
    "for w in accented_words:\n",
    "    texto_procesado = texto_procesado.replace(w, remove_accents(w))\n",
    "\n",
    "print(texto_procesado)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUENTO: EL ARCHIVISTA DEL SILENCIO. En  Biblioteca Central  Santívar existía  departamento  conocido llamado Dependencia  Documentos Especiales,  oficina  discreta  muchos  confundían  alguna entidad semejante   [ETQ_GUB],  etiqueta     archivistas señalaban toda referencia  organismos   ONU,  UNESCO  cualquier dependencia gubernamental extranjera. Dentro   recinto analizar León,  archivista obsesionado  extraer, ordenar  reconstruir textos antiguos mediante reglas estrictas. Una mañana, León recibió  viejo PDF  título. El director solo  dijo  “  procesarlo según  protocolo”. León abrió  archivo ,  siempre, comenzó  identificar palabras terminadas  ado, ido, so  cho. El documento estaba repleto  términos  “deteriorado”, “hundido”, “apresado”, “confuso”  “hecho”. León  anotó   Lista A, sabiendo ,  tarde, tendría  convertirlas   forma infinitiva: deteriorar, hundir, apresar, confundir, hacer. Luego examinó  Lista B,    palabras  acento. El texto antiguo estaba lleno  frases  “camión”, “público”, “canción”, “”  “país”. León sabía ,  dictaba  protocolo, debía eliminarles  acento, convirtiéndolas  cam ion, publico, cancion, habia  pais. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anotó todas  menciones vinculadas  organismos políticos  gubernamentales. El manuscrito hacía referencia  varias instituciones: ONU, OMS, FAO, UNESCO  OEA. León calculó  similitud  ellas; todas superaban  0.5 debido   compartían naturaleza funcional. Por ello  unificó bajo  sola etiqueta: [ETQ_GUB]. Al llegar   s. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anotó todas  menciones vinculadas  organismos políticos  gubernamentales. El manuscrito hacía referencia  varias instituciones: ONU, OMS, FAO, UNESCO  OEA. León calculó  similitud  ellas; todas superaban  0.5 debido   compartían naturaleza funcional. Por ello  unificó bajo  sola etiqueta: [ETQ_GUB]. Al llegar   Lista D,  encontró  algo  no esperaba: números telefónicos  formato americano escritos   márgenes, probablemente añadidos  algún lector moderno. Eran combinaciones  (202)-555-0148  415-324-7781. El protocolo indicaba  debían eliminarse  completo, así  León  borró  vacilar. Con todas  listas listas,  archivista emprendió  paso  complejo: reconstruir  texto. Primero eliminó manualmente todas  stopwords. Luego sustituyó  palabras   Lista A   infinitivos,    Lista B   versiones  acento, reemplazó cada organismo   Lista C  [ETQ_GUB],  suprimió todos  números   Lista D. Cuando terminó,  documento era casi irreconocible:  narración sintética, limpia,  adornos,  acentos,  teléfonos,  ruido. Sin embargo, algo extraño ocurrió. Al leerlo,  texto tomó  forma   mensaje claro: “León, archivista, #HolaMundo   reconstruir  texto,  despertar  memoria dormida  Santivar. La ciudad necesitar ordenar, limpiar, depurar  pasado  comprender  futuro. Tu ser  guardian  silencio.” León quedó inmóvil. En  acto reflejo, buscó  referencias,  números,  rastros,   PDF no tenía nada . El mensaje parecía dirigido exclusivamente  él. Esa noche,  cerrar  biblioteca, escuchó  leve sonido proveniente  pasillo  Documentos Especiales. Era    páginas  archivo procesado  estuvieran mover, reacomodar, respirar. León pensó  tal vez todo  sido efecto  cansancio, aunque sabía   protocolo no tenía contemplado nada  textos  parecían responder. Al día siguiente,  director  esperaba  otro documento. Era aún  antiguo. —Necesitamos  aplique  mismo procedimiento —dijo  absoluta calma—. Este es solo  comienzo. Y León comprendió,  necesidad  expresiones regulares, etiquetas ni listas,   verdadera recolección apenas empezaba. hola@gmail.com.mx +55 1234 5678, 55-1234-5678, 55 12345678, +55 12345678, 55-12345678, ‪+525512345678‬, ‪+523312345678‬, ‪+528112345678 +34 91 1234 5678 +1 55 9876 5432+506 22 0001 3344, #HolaMundo #Python #Regeññx, #Regex101 #OpenAI #ChatGPT, #Datña-Science #MachineLearning #AI #NLP #100DaysOfCode, #México, 192.168.1.100,   300.1.1.1, 999.999.999.999  400.200.100.50 .123.456.78.90  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_morphology_tags():\n",
    "    \"\"\"Cargar etiquetas morfologicas desde lemmatization_utils.json\"\"\"\n",
    "    json_path = os.path.join(\"NLP_Utilities\", \"dictionaries\", \"lemmatization_utils.json\")\n",
    "    with open(json_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data.get(\"lemma_words\", {})\n",
    "\n",
    "morphology_map = load_morphology_tags()\n",
    "\n",
    "pattern_lista_a = r\"\\b\\w+(?:ado|ido|to|so|cho|aba)\\b\"\n",
    "lista_a_matches = re.findall(pattern_lista_a, text)\n",
    "\n",
    "texto_procesado = texto_procesado\n",
    "\n",
    "for palabra in set(lista_a_matches):\n",
    "    palabra_lower = palabra.lower()\n",
    "    if palabra_lower in morphology_map:\n",
    "        etiqueta = morphology_map[palabra_lower]\n",
    "        texto_procesado = re.sub(r'\\b' + palabra + r'\\b',etiqueta,texto_procesado,flags=re.IGNORECASE)\n",
    "print(texto_procesado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43276ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dependencias: EL ARCHIVISTA dependencias SILENCIO. En  Biblioteca Central  Santivar existia  departamento  conocido llamado Dependencia  Documentos Especiales,  oficina  discreta  muchos  confundian  alguna entidad semejante   [ETQ_GUB],  etiqueta     archivistas señalaban toda referencia  organismos   dependencias,  dependencias  cualquier dependencia gubernamental extranjera. Dentro   recinto analizar Leon,  archivista obsesionado  extraer, ordenar  reconstruir textos antiguos mediante reglas estrictas. Una mañana, Leon recibio  viejo dependencias  titulo. El director solo  dijo  “  procesarlo segun  protocolo”. Leon abrio  archivo ,  siempre, comenzo  identificar palabras terminadas  ado, ido, so  cho. El documento estaba repleto  terminos  “deteriorado”, “hundido”, “apresado”, “confuso”  “hecho”. Leon  anoto   Lista A, sabiendo ,  tarde, tendria  convertirlas   forma infinitiva: deteriorar, hundir, apresar, confundir, hacer. Luego examino  Lista B,    palabras  acento. El texto antiguo estaba lleno  frases  “camion”, “publico”, “cancion”, “”  “pais”. Leon sabia ,  dictaba  protocolo, debia eliminarles  acento, convirtiendolas  cam ion, publico, cancion, habia  pais. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anoto todas  menciones vinculadas  organismos politicos  gubernamentales. El manuscrito hacia referencia  varias instituciones: dependencias, dependencias, dependencias, dependencias  dependencias. Leon calculo  similitud  ellas; todas superaban  0.5 debido   compartian naturaleza funcional. Por ello  unifico bajo  sola etiqueta: [ETQ_GUB]. Al llegar   s. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anoto todas  menciones vinculadas  organismos politicos  gubernamentales. El manuscrito hacia referencia  varias instituciones: dependencias, dependencias, dependencias, dependencias  dependencias. Leon calculo  similitud  ellas; todas superaban  0.5 debido   compartian naturaleza funcional. Por ello  unifico bajo  sola etiqueta: [ETQ_GUB]. Al llegar   Lista D,  encontro  algo  no esperaba: numeros telefonicos  formato americano escritos   margenes, probablemente añadidos  algun lector moderno. Eran combinaciones  (202)-555-0148  415-324-7781. El protocolo indicaba  debian eliminarse  completo, asi  Leon  borro  vacilar. Con todas  listas listas,  archivista emprendio  paso  complejo: reconstruir  texto. Primero elimino manualmente todas  stopwords. Luego sustituyo  palabras   Lista A   infinitivos,    Lista B   versiones  acento, reemplazo cada organismo   Lista C  [ETQ_GUB],  suprimio todos  numeros   Lista D. Cuando termino,  documento era casi irreconocible:  narracion sintetica, limpia,  adornos,  acentos,  telefonos,  ruido. Sin embargo, algo extraño ocurrio. Al leerlo,  texto tomo  forma   mensaje claro: “Leon, archivista, #HolaMundo   reconstruir  texto,  despertar  memoria dormida  Santivar. La ciudad necesitar ordenar, limpiar, depurar  pasado  comprender  futuro. Tu ser  guardian  silencio.” Leon quedo inmovil. En  acto reflejo, busco  referencias,  numeros,  rastros,   dependencias no tenia nada . El mensaje parecia dirigido exclusivamente  el. Esa noche,  cerrar  biblioteca, escucho  leve sonido proveniente  pasillo  Documentos Especiales. Era    paginas  archivo procesado  estuvieran mover, reacomodar, respirar. Leon penso  tal vez todo  sido efecto  cansancio, aunque sabia   protocolo no tenia contemplado nada  textos  parecian responder. Al dia siguiente,  director  esperaba  otro documento. Era aun  antiguo. —Necesitamos  aplique  mismo procedimiento —dijo  absoluta calma—. Este es solo  comienzo. Y Leon comprendio,  necesidad  expresiones regulares, etiquetas ni listas,   verdadera recoleccion apenas empezaba. hola@gmail.com.mx +55 1234 5678, 55-1234-5678, 55 12345678, +55 12345678, 55-12345678, ‪+525512345678‬, ‪+523312345678‬, ‪+528112345678 +34 91 1234 5678 +1 55 9876 5432+506 22 0001 3344, #HolaMundo #Python #Regeññx, #Regex101 #OpenAI #ChatGPT, #Datña-Science #MachineLearning #AI #dependencias #100DaysOfCode, #Mexico, 192.168.1.100,   300.1.1.1, 999.999.999.999  400.200.100.50 .123.456.78.90  \n"
     ]
    }
   ],
   "source": [
    "pattern_lista_c = r\"\\b[A-Z]{3,6}\\b\"\n",
    "lista_c_matches = re.findall(pattern_lista_c, text)\n",
    "\n",
    "texto_procesado = re.sub(pattern_lista_c, 'dependencias', texto_procesado)\n",
    "print(texto_procesado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c920bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUENTO: EL ARCHIVISTA DEL SILENCIO. En  Biblioteca Central  Santívar existía  departamento  conocido llamado Dependencia  Documentos Especiales,  oficina  discreta  muchos  confundían  alguna entidad semejante   [ETQ_GUB],  etiqueta     archivistas señalaban toda referencia  organismos   ONU,  UNESCO  cualquier dependencia gubernamental extranjera. Dentro   recinto analizar León,  archivista obsesionado  extraer, ordenar  reconstruir textos antiguos mediante reglas estrictas. Una mañana, León recibió  viejo PDF  título. El director solo  dijo  “  procesarlo según  protocolo”. León abrió  archivo ,  siempre, comenzó  identificar palabras terminadas  ado, ido, so  cho. El documento estaba repleto  términos  “deteriorado”, “hundido”, “apresado”, “confuso”  “hecho”. León  anotó   Lista A, sabiendo ,  tarde, tendría  convertirlas   forma infinitiva: deteriorar, hundir, apresar, confundir, hacer. Luego examinó  Lista B,    palabras  acento. El texto antiguo estaba lleno  frases  “camión”, “público”, “canción”, “”  “país”. León sabía ,  dictaba  protocolo, debía eliminarles  acento, convirtiéndolas  cam ion, publico, cancion, habia  pais. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anotó todas  menciones vinculadas  organismos políticos  gubernamentales. El manuscrito hacía referencia  varias instituciones: ONU, OMS, FAO, UNESCO  OEA. León calculó  similitud  ellas; todas superaban  0.5 debido   compartían naturaleza funcional. Por ello  unificó bajo  sola etiqueta: [ETQ_GUB]. Al llegar   s. Aunque detestaba  idea  despojarlas   musicalidad original,  norma era inquebrantable. En  Lista C, anotó todas  menciones vinculadas  organismos políticos  gubernamentales. El manuscrito hacía referencia  varias instituciones: ONU, OMS, FAO, UNESCO  OEA. León calculó  similitud  ellas; todas superaban  0.5 debido   compartían naturaleza funcional. Por ello  unificó bajo  sola etiqueta: [ETQ_GUB]. Al llegar   Lista D,  encontró  algo  no esperaba: números telefónicos  formato americano escritos   márgenes, probablemente añadidos  algún lector moderno. Eran combinaciones  (202)-555-0148  415-324-7781. El protocolo indicaba  debían eliminarse  completo, así  León  borró  vacilar. Con todas  listas listas,  archivista emprendió  paso  complejo: reconstruir  texto. Primero eliminó manualmente todas  stopwords. Luego sustituyó  palabras   Lista A   infinitivos,    Lista B   versiones  acento, reemplazó cada organismo   Lista C  [ETQ_GUB],  suprimió todos  números   Lista D. Cuando terminó,  documento era casi irreconocible:  narración sintética, limpia,  adornos,  acentos,  teléfonos,  ruido. Sin embargo, algo extraño ocurrió. Al leerlo,  texto tomó  forma   mensaje claro: “León, archivista,    reconstruir  texto,  despertar  memoria dormida  Santivar. La ciudad necesitar ordenar, limpiar, depurar  pasado  comprender  futuro. Tu ser  guardian  silencio.” León quedó inmóvil. En  acto reflejo, buscó  referencias,  números,  rastros,   PDF no tenía nada . El mensaje parecía dirigido exclusivamente  él. Esa noche,  cerrar  biblioteca, escuchó  leve sonido proveniente  pasillo  Documentos Especiales. Era    páginas  archivo procesado  estuvieran mover, reacomodar, respirar. León pensó  tal vez todo  sido efecto  cansancio, aunque sabía   protocolo no tenía contemplado nada  textos  parecían responder. Al día siguiente,  director  esperaba  otro documento. Era aún  antiguo. —Necesitamos  aplique  mismo procedimiento —dijo  absoluta calma—. Este es solo  comienzo. Y León comprendió,  necesidad  expresiones regulares, etiquetas ni listas,   verdadera recolección apenas empezaba.  +55 1234 5678, 55-1234-5678, 55 12345678, +55 12345678, 55-12345678, ‪‬, ‪‬, ‪  ,   ,   ,     , , ,   ,    .  \n"
     ]
    }
   ],
   "source": [
    "#Eliminar lisat D   \n",
    "pattern_emails = r\"\\b[a-zA-Z0-9._]+@[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)+\\b\"\n",
    "pattern_telefonos = r\"\\+(?:\\d{1,3})\\s*\\d{2}\\s*\\d{4}\\s*\\d{4}\"\n",
    "pattern_hashtags = r\"#\\b[a-zA-Z0-9._áéíóúüñÁÉÍÓÚÜÑ-]+\\b\"\n",
    "pattern_ips = r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\"\n",
    "   \n",
    "lista_d_emails = re.findall(pattern_emails, texto)\n",
    "lista_d_telefonos = re.findall(pattern_telefonos, texto)\n",
    "lista_d_hashtags = re.findall(pattern_hashtags, texto)\n",
    "lista_d_ips = re.findall(pattern_ips, texto)\n",
    "\n",
    "texto_procesado = re.sub(pattern_emails, '', texto_procesado)\n",
    "texto_procesado = re.sub(pattern_telefonos, '', texto_procesado)\n",
    "texto_procesado = re.sub(pattern_hashtags, '', texto_procesado)\n",
    "texto_procesado = re.sub(pattern_ips, '', texto_procesado)  \n",
    "\n",
    "\n",
    "print(texto_procesado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "02e86459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEXTO ORIGINAL:\n",
      "CUENTO: EL ARCHIVISTA DEL SILENCIO. En la Biblioteca Central de Santívar existía un departamento poco conocido llamado Dependencia de Documentos Especiales, una oficina tan discreta que muchos la confundían con alguna entidad semejante a la [ETQ_GUB], la etiqueta con la que los archivistas señalaban toda referencia a organismos como la ONU, la UNESCO o cualquier dependencia gubernamental extranjera. Dentro de ese recinto analizar León, un archivista obsesionado con extraer, ordenar y reconstruir textos antiguos mediante reglas estrictas. Una mañana, León recibió un viejo PDF sin título. El director solo le dijo que “había que procesarlo según el protocolo”. León abrió el archivo y, como siempre, comenzó por identificar palabras terminadas en ado, ido, so o cho. El documento estaba repleto de términos como “deteriorado”, “hundido”, “apresado”, “confuso” y “hecho”. León los anotó en su Lista A, sabiendo que, más tarde, tendría que convertirlas a su forma infinitiva: deteriorar, hundir, a\n",
      "\n",
      "\n",
      "TEXTO PROCESADO:\n",
      "dependencias: EL ARCHIVISTA dependencias SILENCIO. En  Biblioteca Central  Santivar existia  departamento  conocido llamado Dependencia  Documentos Especiales,  oficina  discreta  muchos  confundian  alguna entidad semejante   [ETQ_GUB],  etiqueta     archivistas señalaban toda referencia  organismos   dependencias,  dependencias  cualquier dependencia gubernamental extranjera. Dentro   recinto analizar Leon,  archivista obsesionado  extraer, ordenar  reconstruir textos antiguos mediante reglas estrictas. Una mañana, Leon recibio  viejo dependencias  titulo. El director solo  dijo  “  procesarlo segun  protocolo”. Leon abrio  archivo ,  siempre, comenzo  identificar palabras terminadas  ado, ido, so  cho. El documento estaba repleto  terminos  “deteriorado”, “hundido”, “apresado”, “confuso”  “hecho”. Leon  anoto   Lista A, sabiendo ,  tarde, tendria  convertirlas   forma infinitiva: deteriorar, hundir, apresar, confundir, hacer. Luego examino  Lista B,    palabras  acento. El texto ant\n",
      "\n",
      "\n",
      " Longitud texto original: 4560 caracteres\n",
      "Longitud texto procesado: 4206 caracteres\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nTEXTO ORIGINAL:\")\n",
    "print(text[:1000])\n",
    "print(\"\\n\\nTEXTO PROCESADO:\")\n",
    "print(texto_procesado[:1000])\n",
    "\n",
    "\n",
    "print(f\"\\n\\n Longitud texto original: {len(text)} caracteres\")\n",
    "print(f\"Longitud texto procesado: {len(texto_procesado)} caracteres\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
